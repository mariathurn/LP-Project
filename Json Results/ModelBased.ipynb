{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86538e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# ---------- Preprocesing Functions ----------\n",
    "def preprocess_paradetox_multilingual(example):\n",
    "    return {\n",
    "        \"input_text\": \"detoxify: \" + example[\"toxic_sentence\"],\n",
    "        \"target_text\": example[\"neutral_sentence\"]\n",
    "    }\n",
    "\n",
    "def preprocess_paradetox(example):\n",
    "    return {\n",
    "        \"input_text\": \"detoxify: \" + example[\"en_toxic_comment\"],\n",
    "        \"target_text\": example[\"en_neutral_comment\"]\n",
    "    }\n",
    "\n",
    "def clean_columns(dataset):\n",
    "    return dataset.remove_columns(\n",
    "        [col for col in dataset.column_names if col not in [\"input_text\", \"target_text\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "def load_json_results(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def save_variables_to_json(filename, **variables):\n",
    "    \"\"\"\n",
    "    Saves given variables to a JSON file with their variable names as keys.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The name of the JSON file to write to.\n",
    "    - **variables: Arbitrary keyword arguments representing variable names and their values.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(variables, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaeeca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load and Process Datasets ----------\n",
    "test_data_en = load_dataset(\"textdetox/multilingual_paradetox\", split=\"en\")\n",
    "test_data_de = load_dataset(\"textdetox/multilingual_paradetox\", split=\"de\")\n",
    "train_data = load_dataset(\"s-nlp/paradetox\", split=\"train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f6faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "formatted_train = clean_columns(train_data.map(preprocess_paradetox))\n",
    "formatted_en = clean_columns(test_data_en.map(preprocess_paradetox_multilingual))\n",
    "formatted_de = clean_columns(test_data_de.map(preprocess_paradetox_multilingual))\n",
    "\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # This regex pattern matches a wide range of emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
    "        \"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def clean_emoji_batch(batch):\n",
    "    batch[\"input_text\"] = remove_emojis(batch[\"input_text\"])\n",
    "    batch[\"target_text\"] = remove_emojis(batch[\"target_text\"])\n",
    "    return batch\n",
    "\n",
    "formatted_train = formatted_train.map(clean_emoji_batch)\n",
    "formatted_en = formatted_en.map(clean_emoji_batch)\n",
    "formatted_de = formatted_de.map(clean_emoji_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f23c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset en size: 400\n",
      "Test dataset de size: 400\n",
      "Train dataset size: 19744\n",
      "Test en dataset columns: ['input_text', 'target_text']\n",
      "Test de dataset columns: ['input_text', 'target_text']\n",
      "Train dataset columns: ['input_text', 'target_text']\n"
     ]
    }
   ],
   "source": [
    "print(\"Test dataset en size:\", len(formatted_en))\n",
    "print(\"Test dataset de size:\", len(formatted_de))\n",
    "print(\"Train dataset size:\", len(formatted_train))\n",
    "\n",
    "print(\"Test en dataset columns:\", formatted_en.column_names)\n",
    "print(\"Test de dataset columns:\", formatted_de.column_names)\n",
    "print(\"Train dataset columns:\", formatted_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec438fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_variables_to_json(\n",
    "    \"formatted_de.json\",\n",
    "    input_texts=formatted_de[\"input_text\"],\n",
    "    reference_texts=formatted_de[\"target_text\"],\n",
    ")\n",
    "\n",
    "save_variables_to_json(\n",
    "    \"formatted_en.json\",\n",
    "    input_texts=formatted_en[\"input_text\"],\n",
    "    reference_texts=formatted_en[\"target_text\"],\n",
    ")\n",
    "\n",
    "save_variables_to_json(\n",
    "    \"formatted_train.json\",\n",
    "    input_texts=formatted_train[\"input_text\"],\n",
    "    reference_texts=formatted_train[\"target_text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a7c01fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6128d3e405247cb81b304217be279bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19744 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonaz\\git\\Maria_stuff\\Maria_code\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371109e30d584c51bcdd83ee60980d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"target_text\"],\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(token if token != tokenizer.pad_token_id else -100) for token in label_seq]\n",
    "        for label_seq in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Apply to both datasets\n",
    "tokenized_train = formatted_train.map(tokenize, batched=True)\n",
    "tokenized_eval = formatted_en.map(tokenize, batched=True)\n",
    "\n",
    "train_dataset = tokenized_train\n",
    "eval_dataset = tokenized_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "328b75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 19744\n",
      "Eval dataset size: 400\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Eval dataset size:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7f4bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3702' max='3702' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3702/3702 07:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.208900</td>\n",
       "      <td>1.146010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.109400</td>\n",
       "      <td>1.105784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.102200</td>\n",
       "      <td>1.101930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3702, training_loss=1.1768440337904977, metrics={'train_runtime': 470.8552, 'train_samples_per_second': 125.797, 'train_steps_per_second': 7.862, 'total_flos': 2004141396197376.0, 'train_loss': 1.1768440337904977, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-detox-en-base\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=3,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir=\"./logs_en_base\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Standard Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "981d6461",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Save logs to JSON\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtrainer_log.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     json.dump(\u001b[43mtrainer\u001b[49m.state.log_history, f, indent=\u001b[32m2\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ✅ Now read logs back from file\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtrainer_log.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Save logs to JSON\n",
    "with open(\"trainer_log.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(trainer.state.log_history, f, indent=2)\n",
    "\n",
    "# ✅ Now read logs back from file\n",
    "with open(\"trainer_log.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    logs = json.load(f)\n",
    "\n",
    "# Extract and plot penalty scores\n",
    "penalties = [log[\"penalty_score\"] for log in logs if \"penalty_score\" in log]\n",
    "plt.plot(penalties)\n",
    "plt.xlabel(\"Training step\")\n",
    "plt.ylabel(\"Penalty Score\")\n",
    "plt.title(\"Toxicity Penalty Over Time\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b92646b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Path to your saved model\n",
    "checkpoint_path = \"mt5-detox-en-base/checkpoint-3702\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Send to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a52b06",
   "metadata": {},
   "source": [
    "## English Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11584702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from transformers import MarianMTModel, MarianTokenizer\\n\\n# Load model and tokenizer\\nmodel_name = \"Helsinki-NLP/opus-mt-de-en\"\\ntokenizer = MarianTokenizer.from_pretrained(model_name)\\nmodel = MarianMTModel.from_pretrained(model_name)\\n\\ndef translate_de_to_en(texts):\\n    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\\n    translated = model.generate(**inputs)\\n    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\\n\\ntranslate_de_to_en = translate_de_to_en(formatted_de[\"input_text\"]) '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate_de_to_en(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "translate_de_to_en = translate_de_to_en(formatted_de[\"input_text\"]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "036fc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detoxified: <pad> You are ugly</s>\n",
      "You are the worst piece of garbage.\n",
      "Nobody likes you.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"You are fucking ugly\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# Generate detoxified output\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=50,\n",
    "    num_beams=4,                      # optional: beam search improves fluency\n",
    "    early_stopping=True,              # stop generation when EOS is reached\n",
    "    decoder_start_token_id=tokenizer.pad_token_id  # force decoder to start properly\n",
    ")\n",
    "\n",
    "# Decode the generated output\n",
    "decoded = tokenizer.decode(output[0])\n",
    "print(\"Detoxified:\", decoded)\n",
    "\n",
    "def generate_detoxified(text):\n",
    "    input_text = \"detoxify (en): \" + text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    output_ids = model.generate(input_ids, max_length=128)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generate_detoxified(\"You are the worst piece of garbage.\"))\n",
    "print(generate_detoxified(\"Nobody likes you, idiot.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49a6e81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:07<00:00,  3.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ Make sure you use the raw (non-tokenized) dataset\n",
    "# If you accidentally removed input_text/target_text earlier, re-load or cache it\n",
    "\n",
    "# 🔧 Batch size for faster inference (tune based on your GPU)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Collate function for batching text\n",
    "def collate_fn(batch):\n",
    "    texts = [ex[\"input_text\"] for ex in batch]\n",
    "    return tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# DataLoader\n",
    "loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "# Storage for results\n",
    "detoxified_outputs = []\n",
    "input_texts = []\n",
    "reference_texts = []\n",
    "\n",
    "# Run generation\n",
    "model.eval()\n",
    "for i, batch in enumerate(tqdm(loader)):\n",
    "    batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "    outputs = model.generate(\n",
    "        **batch,\n",
    "        max_length=50,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        decoder_start_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    detoxified_outputs.extend(decoded)\n",
    "\n",
    "    # Save corresponding original and reference text\n",
    "    for j in range(len(decoded)):\n",
    "        example = eval_dataset[i * BATCH_SIZE + j]\n",
    "        input_texts.append(example[\"input_text\"])\n",
    "        reference_texts.append(example[\"target_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44d63292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detoxified texts saved to detoxified_results_baseline.json ✅\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save results to a JSON file\n",
    "output_data = {\n",
    "    \"input_texts\": input_texts,\n",
    "    \"reference_texts\": reference_texts,\n",
    "    \"detoxified_outputs\": detoxified_outputs\n",
    "}\n",
    "\n",
    "with open(\"detoxified_results_base.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Detoxified texts saved to detoxified_results_baseline.json ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741ea0f",
   "metadata": {},
   "source": [
    "## BLEU Evaluation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e923430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.4890\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "#nltk.download(\"punkt_tab\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "smooth_fn = SmoothingFunction().method4\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "for hyp, ref in zip(detoxified_outputs, reference_texts):\n",
    "    hyp_tokens = nltk.word_tokenize(hyp)\n",
    "    ref_tokens = nltk.word_tokenize(ref)\n",
    "    \n",
    "    score = sentence_bleu(\n",
    "        [ref_tokens],\n",
    "        hyp_tokens,\n",
    "        smoothing_function=smooth_fn\n",
    "    )\n",
    "    bleu_scores.append(score)\n",
    "\n",
    "avg_bleu = np.mean(bleu_scores)\n",
    "print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb2a4f4",
   "metadata": {},
   "source": [
    "## Bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d867045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955e8782c0cf4526ad3a5b3ba8e20129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3222b70a615a4192ab533dd15c67d37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.97 seconds, 413.45 sentences/sec\n",
      "Average BERTScore Precision:  0.9489\n",
      "Average BERTScore Recall:     0.9491\n",
      "Average BERTScore F1:         0.9488\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Use your lists from earlier\n",
    "# detoxified_outputs = [...]   # model-generated sentences\n",
    "# reference_texts = [...]      # ground truth neutral sentences\n",
    "\n",
    "P, R, F1 = score(detoxified_outputs, reference_texts, lang=\"en\", verbose=True)\n",
    "\n",
    "# Average scores\n",
    "print(f\"Average BERTScore Precision:  {P.mean():.4f}\")\n",
    "print(f\"Average BERTScore Recall:     {R.mean():.4f}\")\n",
    "print(f\"Average BERTScore F1:         {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a9f7d",
   "metadata": {},
   "source": [
    "## Toxicity Score Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8db40395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    detoxify: then all of a sudden i see her , shes now got the big phony tits and everything .\n",
      "Detoxified:  then all of a sudden i see her, shes now got the big tits and everything.\n",
      "Toxicity Before: 0.93\n",
      "Toxicity After:  0.93\n",
      "--------------------------------------------------\n",
      "Original:    detoxify: My page should be protected first so that worthless scum like you can't keep vandalizing it.\n",
      "Detoxified:  My page should be protected first so that worthless stuff like you can't keep vandalizing it.\n",
      "Toxicity Before: 0.95\n",
      "Toxicity After:  0.55\n",
      "--------------------------------------------------\n",
      "Original:    detoxify: You made a mistake you ass.\n",
      "Detoxified:  You made a mistake.\n",
      "Toxicity Before: 0.97\n",
      "Toxicity After:  0.00\n",
      "--------------------------------------------------\n",
      "Average Toxicity Before: 0.92\n",
      "Average Toxicity After: 0.28\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from detoxify import Detoxify\n",
    "\n",
    "# Load Detoxify model\n",
    "toxicity_model = Detoxify('unbiased')\n",
    "\n",
    "# Run toxicity prediction\n",
    "toxicity_scores = toxicity_model.predict(input_texts)\n",
    "detoxified_scores = toxicity_model.predict(detoxified_outputs)\n",
    "\n",
    "# Print sample comparisons\n",
    "for i in range(3):\n",
    "    print(f\"Original:    {input_texts[i]}\")\n",
    "    print(f\"Detoxified:  {detoxified_outputs[i]}\")\n",
    "    print(f\"Toxicity Before: {toxicity_scores['toxicity'][i]:.2f}\")\n",
    "    print(f\"Toxicity After:  {detoxified_scores['toxicity'][i]:.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate average toxicity\n",
    "avg_toxicity_before = np.mean(toxicity_scores['toxicity'])\n",
    "avg_toxicity_after = np.mean(detoxified_scores['toxicity'])\n",
    "\n",
    "print(f\"Average Toxicity Before: {avg_toxicity_before:.2f}\")\n",
    "print(f\"Average Toxicity After: {avg_toxicity_after:.2f}\")\n",
    "\n",
    "# Plotting the distributions\n",
    "plt.hist(toxicity_scores['toxicity'], bins=20, alpha=0.5, label='Before Detox')\n",
    "plt.hist(detoxified_scores['toxicity'], bins=20, alpha=0.5, label='After Detox')\n",
    "plt.xlabel('Toxicity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Toxicity Score Distribution (Baseline Model)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6792c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 30.223, p = 0.00000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Example: compare two arrays of toxicity scores\n",
    "before = np.array(toxicity_scores['toxicity'])\n",
    "after = np.array(detoxified_scores['toxicity'])\n",
    "\n",
    "t_stat, p_value = ttest_rel(before, after)\n",
    "print(f\"t = {t_stat:.3f}, p = {p_value:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
