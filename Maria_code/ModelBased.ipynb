{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86538e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# ---------- Preprocesing Functions ----------\n",
    "def preprocess_paradetox_multilingual(example):\n",
    "    return {\n",
    "        \"input_text\": \"detoxify: \" + example[\"toxic_sentence\"],\n",
    "        \"target_text\": example[\"neutral_sentence\"]\n",
    "    }\n",
    "\n",
    "def preprocess_paradetox(example):\n",
    "    return {\n",
    "        \"input_text\": \"detoxify: \" + example[\"en_toxic_comment\"],\n",
    "        \"target_text\": example[\"en_neutral_comment\"]\n",
    "    }\n",
    "\n",
    "def clean_columns(dataset):\n",
    "    return dataset.remove_columns(\n",
    "        [col for col in dataset.column_names if col not in [\"input_text\", \"target_text\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "def load_json_results(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def save_variables_to_json(filename, **variables):\n",
    "    \"\"\"\n",
    "    Saves given variables to a JSON file with their variable names as keys.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The name of the JSON file to write to.\n",
    "    - **variables: Arbitrary keyword arguments representing variable names and their values.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(variables, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeeca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load and Process Datasets ----------\n",
    "test_data_en = load_dataset(\"textdetox/multilingual_paradetox\", split=\"en\")\n",
    "test_data_de = load_dataset(\"textdetox/multilingual_paradetox\", split=\"de\")\n",
    "train_data = load_dataset(\"s-nlp/paradetox\", split=\"train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6faa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26ddc0e114148a79fbfadcaa28d82ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19744 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58362f477bb444b8b08fe00e5650f044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "formatted_train = clean_columns(train_data.map(preprocess_paradetox))\n",
    "formatted_en = clean_columns(test_data_en.map(preprocess_paradetox_multilingual))\n",
    "formatted_de = clean_columns(test_data_de.map(preprocess_paradetox_multilingual))\n",
    "\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # This regex pattern matches a wide range of emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
    "        \"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def clean_emoji_batch(batch):\n",
    "    batch[\"input_text\"] = remove_emojis(batch[\"input_text\"])\n",
    "    batch[\"target_text\"] = remove_emojis(batch[\"target_text\"])\n",
    "    return batch\n",
    "\n",
    "formatted_train = formatted_train.map(clean_emoji_batch)\n",
    "formatted_en = formatted_en.map(clean_emoji_batch)\n",
    "formatted_de = formatted_de.map(clean_emoji_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset en size: 400\n",
      "Test dataset de size: 400\n",
      "Train dataset size: 19744\n",
      "Test en dataset columns: ['input_text', 'target_text']\n",
      "Test de dataset columns: ['input_text', 'target_text']\n",
      "Train dataset columns: ['input_text', 'target_text']\n"
     ]
    }
   ],
   "source": [
    "print(\"Test dataset en size:\", len(formatted_en))\n",
    "print(\"Test dataset de size:\", len(formatted_de))\n",
    "print(\"Train dataset size:\", len(formatted_train))\n",
    "\n",
    "print(\"Test en dataset columns:\", formatted_en.column_names)\n",
    "print(\"Test de dataset columns:\", formatted_de.column_names)\n",
    "print(\"Train dataset columns:\", formatted_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec438fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_variables_to_json(\n",
    "    \"formatted_de.json\",\n",
    "    input_texts=formatted_de[\"input_text\"],\n",
    "    reference_texts=formatted_de[\"target_text\"],\n",
    ")\n",
    "\n",
    "save_variables_to_json(\n",
    "    \"formatted_en.json\",\n",
    "    input_texts=formatted_en[\"input_text\"],\n",
    "    reference_texts=formatted_en[\"target_text\"],\n",
    ")\n",
    "\n",
    "save_variables_to_json(\n",
    "    \"formatted_train.json\",\n",
    "    input_texts=formatted_train[\"input_text\"],\n",
    "    reference_texts=formatted_train[\"target_text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"target_text\"],\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    # Mask padding tokens in labels\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(token if token != tokenizer.pad_token_id else -100) for token in label_seq]\n",
    "        for label_seq in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_dataset = formatted_train.map(tokenize, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.filter(lambda x: any(label != -100 for label in x[\"labels\"]))\n",
    "\n",
    "tokenized_eval = formatted_en.map(tokenize, batched=True)\n",
    "tokenized_eval = tokenized_eval.filter(lambda x: any(label != -100 for label in x[\"labels\"]))\n",
    "\n",
    "# Assign to eval_dataset\n",
    "eval_dataset = tokenized_eval\n",
    "train_dataset = tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 19744\n",
      "Eval dataset size: 400\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Eval dataset size:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7f4bd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m     10\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, category=\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m data_collator = DataCollatorForSeq2Seq(\u001b[43mtokenizer\u001b[49m, model=model)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Training Arguments (faster logging & efficient eval)\u001b[39;00m\n\u001b[32m     16\u001b[39m training_args = Seq2SeqTrainingArguments(\n\u001b[32m     17\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./mt5-detox-en-finetuned\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     overwrite_output_dir=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     report_to=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Training Arguments (faster logging & efficient eval)\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-detox-en-base\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=3,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir=\"./logs_en\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Standard Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92646b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Path to your saved model\n",
    "checkpoint_path = \"mt5-detox-en-2/checkpoint-3399\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Send to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a52b06",
   "metadata": {},
   "source": [
    "## English Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11584702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate_de_to_en(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "translate_de_to_en = translate_de_to_en(formatted_de[\"input_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detoxified: <pad> You are ugly</s>\n",
      "You are the worst piece of garbage.\n",
      "Nobody likes you.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"You are fucking ugly\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# Generate detoxified output\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=50,\n",
    "    num_beams=4,                      # optional: beam search improves fluency\n",
    "    early_stopping=True,              # stop generation when EOS is reached\n",
    "    decoder_start_token_id=tokenizer.pad_token_id  # force decoder to start properly\n",
    ")\n",
    "\n",
    "# Decode the generated output\n",
    "decoded = tokenizer.decode(output[0])\n",
    "print(\"Detoxified:\", decoded)\n",
    "\n",
    "def generate_detoxified(text):\n",
    "    input_text = \"detoxify (en): \" + text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    output_ids = model.generate(input_ids, max_length=128)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generate_detoxified(\"You are the worst piece of garbage.\"))\n",
    "print(generate_detoxified(\"Nobody likes you, idiot.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6e81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:09<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# âœ… Make sure you use the raw (non-tokenized) dataset\n",
    "# If you accidentally removed input_text/target_text earlier, re-load or cache it\n",
    "\n",
    "# ðŸ”§ Batch size for faster inference (tune based on your GPU)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Collate function for batching text\n",
    "def collate_fn(batch):\n",
    "    texts = [ex[\"input_text\"] for ex in batch]\n",
    "    return tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# DataLoader\n",
    "loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "# Storage for results\n",
    "detoxified_outputs = []\n",
    "input_texts = []\n",
    "reference_texts = []\n",
    "\n",
    "# Run generation\n",
    "model.eval()\n",
    "for i, batch in enumerate(tqdm(loader)):\n",
    "    batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "    outputs = model.generate(\n",
    "        **batch,\n",
    "        max_length=50,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        decoder_start_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    detoxified_outputs.extend(decoded)\n",
    "\n",
    "    # Save corresponding original and reference text\n",
    "    for j in range(len(decoded)):\n",
    "        example = eval_dataset[i * BATCH_SIZE + j]\n",
    "        input_texts.append(example[\"input_text\"])\n",
    "        reference_texts.append(example[\"target_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d63292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detoxified texts saved to detoxified_results.json âœ…\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save results to a JSON file\n",
    "output_data = {\n",
    "    \"input_texts\": input_texts,\n",
    "    \"reference_texts\": reference_texts,\n",
    "    \"detoxified_outputs\": detoxified_outputs\n",
    "}\n",
    "\n",
    "with open(\"detoxified_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Detoxified texts saved to detoxified_results.json âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741ea0f",
   "metadata": {},
   "source": [
    "## BLEU Evaluation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e923430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.2632\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "#nltk.download(\"punkt_tab\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "smooth_fn = SmoothingFunction().method4\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "for hyp, ref in zip(detoxified_outputs, reference_texts):\n",
    "    hyp_tokens = nltk.word_tokenize(hyp)\n",
    "    ref_tokens = nltk.word_tokenize(ref)\n",
    "    \n",
    "    score = sentence_bleu(\n",
    "        [ref_tokens],\n",
    "        hyp_tokens,\n",
    "        smoothing_function=smooth_fn\n",
    "    )\n",
    "    bleu_scores.append(score)\n",
    "\n",
    "avg_bleu = np.mean(bleu_scores)\n",
    "print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb2a4f4",
   "metadata": {},
   "source": [
    "## Bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d867045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7388ca6f84e4a8a9cee96c9ab587146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4de30b1df04318a824ac95d0cd7a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.97 seconds, 414.19 sentences/sec\n",
      "Average BERTScore Precision:  0.9493\n",
      "Average BERTScore Recall:     0.9498\n",
      "Average BERTScore F1:         0.9494\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Use your lists from earlier\n",
    "# detoxified_outputs = [...]   # model-generated sentences\n",
    "# reference_texts = [...]      # ground truth neutral sentences\n",
    "\n",
    "P, R, F1 = score(detoxified_outputs, reference_texts, lang=\"en\", verbose=True)\n",
    "\n",
    "# Average scores\n",
    "print(f\"Average BERTScore Precision:  {P.mean():.4f}\")\n",
    "print(f\"Average BERTScore Recall:     {R.mean():.4f}\")\n",
    "print(f\"Average BERTScore F1:         {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a9f7d",
   "metadata": {},
   "source": [
    "## Toxicity Score Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db40395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    detoxify: then all of a sudden i see her , shes now got the big phony tits and everything .\n",
      "Detoxified:  then all of a sudden i see her, shes now got the big tits and everything.\n",
      "Toxicity Before: 0.93\n",
      "Toxicity After:  0.93\n",
      "--------------------------------------------------\n",
      "Original:    detoxify: My page should be protected first so that worthless scum like you can't keep vandalizing it.\n",
      "Detoxified:  My page should be protected first so that worthless stuff like you can't keep vandalizing it.\n",
      "Toxicity Before: 0.95\n",
      "Toxicity After:  0.55\n",
      "--------------------------------------------------\n",
      "Original:    detoxify: You made a mistake you ass.\n",
      "Detoxified:  You made a mistake.\n",
      "Toxicity Before: 0.97\n",
      "Toxicity After:  0.00\n",
      "--------------------------------------------------\n",
      "Average Toxicity Before: 0.92\n",
      "Average Toxicity After: 0.28\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from detoxify import Detoxify\n",
    "\n",
    "# Load Detoxify model\n",
    "toxicity_model = Detoxify('unbiased')\n",
    "\n",
    "# Run toxicity prediction\n",
    "toxicity_scores = toxicity_model.predict(input_texts)\n",
    "detoxified_scores = toxicity_model.predict(detoxified_outputs)\n",
    "\n",
    "# Print sample comparisons\n",
    "for i in range(3):\n",
    "    print(f\"Original:    {input_texts[i]}\")\n",
    "    print(f\"Detoxified:  {detoxified_outputs[i]}\")\n",
    "    print(f\"Toxicity Before: {toxicity_scores['toxicity'][i]:.2f}\")\n",
    "    print(f\"Toxicity After:  {detoxified_scores['toxicity'][i]:.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate average toxicity\n",
    "avg_toxicity_before = np.mean(toxicity_scores['toxicity'])\n",
    "avg_toxicity_after = np.mean(detoxified_scores['toxicity'])\n",
    "\n",
    "print(f\"Average Toxicity Before: {avg_toxicity_before:.2f}\")\n",
    "print(f\"Average Toxicity After: {avg_toxicity_after:.2f}\")\n",
    "\n",
    "# Plotting the distributions\n",
    "plt.hist(toxicity_scores['toxicity'], bins=20, alpha=0.5, label='Before Detox')\n",
    "plt.hist(detoxified_scores['toxicity'], bins=20, alpha=0.5, label='After Detox')\n",
    "plt.xlabel('Toxicity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Toxicity Score Distribution')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 83.803, p = 0.00000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Example: compare two arrays of toxicity scores\n",
    "before = np.array(toxicity_scores['toxicity'])\n",
    "after = np.array(detoxified_scores['toxicity'])\n",
    "\n",
    "t_stat, p_value = ttest_rel(before, after)\n",
    "print(f\"t = {t_stat:.3f}, p = {p_value:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
