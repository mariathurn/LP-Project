{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86538e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# ---------- Preprocesing Functions ----------\n",
    "def preprocess_paradetox_multilingual(example):\n",
    "    return {\n",
    "        \"input_text\": \"detoxify: \" + example[\"toxic_sentence\"],\n",
    "        \"target_text\": example[\"neutral_sentence\"]\n",
    "    }\n",
    "\n",
    "def preprocess_paradetox(example):\n",
    "    return {\n",
    "        \"input_text\": \"detoxify: \" + example[\"en_toxic_comment\"],\n",
    "        \"target_text\": example[\"en_neutral_comment\"]\n",
    "    }\n",
    "\n",
    "def clean_columns(dataset):\n",
    "    return dataset.remove_columns(\n",
    "        [col for col in dataset.column_names if col not in [\"input_text\", \"target_text\"]]\n",
    "    )\n",
    "\n",
    "\n",
    "def load_json_results(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def save_variables_to_json(filename, **variables):\n",
    "    \"\"\"\n",
    "    Saves given variables to a JSON file with their variable names as keys.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The name of the JSON file to write to.\n",
    "    - **variables: Arbitrary keyword arguments representing variable names and their values.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(variables, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaeeca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load and Process Datasets ----------\n",
    "test_data_en = load_dataset(\"textdetox/multilingual_paradetox\", split=\"en\")\n",
    "test_data_de = load_dataset(\"textdetox/multilingual_paradetox\", split=\"de\")\n",
    "train_data = load_dataset(\"s-nlp/paradetox\", split=\"train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "formatted_train = clean_columns(train_data.map(preprocess_paradetox))\n",
    "formatted_en = clean_columns(test_data_en.map(preprocess_paradetox_multilingual))\n",
    "formatted_de = clean_columns(test_data_de.map(preprocess_paradetox_multilingual))\n",
    "\n",
    "\n",
    "def remove_emojis(text):\n",
    "    # This regex pattern matches a wide range of emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
    "        \"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def clean_emoji_batch(batch):\n",
    "    batch[\"input_text\"] = remove_emojis(batch[\"input_text\"])\n",
    "    batch[\"target_text\"] = remove_emojis(batch[\"target_text\"])\n",
    "    return batch\n",
    "\n",
    "formatted_train = formatted_train.map(clean_emoji_batch)\n",
    "formatted_en = formatted_en.map(clean_emoji_batch)\n",
    "formatted_de = formatted_de.map(clean_emoji_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f23c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset en size: 400\n",
      "Test dataset de size: 400\n",
      "Train dataset size: 19744\n",
      "Test en dataset columns: ['input_text', 'target_text']\n",
      "Test de dataset columns: ['input_text', 'target_text']\n",
      "Train dataset columns: ['input_text', 'target_text']\n"
     ]
    }
   ],
   "source": [
    "print(\"Test dataset en size:\", len(formatted_en))\n",
    "print(\"Test dataset de size:\", len(formatted_de))\n",
    "print(\"Train dataset size:\", len(formatted_train))\n",
    "\n",
    "print(\"Test en dataset columns:\", formatted_en.column_names)\n",
    "print(\"Test de dataset columns:\", formatted_de.column_names)\n",
    "print(\"Train dataset columns:\", formatted_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec438fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_variables_to_json(\n",
    "    \"formatted_de.json\",\n",
    "    input_texts=formatted_de[\"input_text\"],\n",
    "    reference_texts=formatted_de[\"target_text\"],\n",
    ")\n",
    "\n",
    "save_variables_to_json(\n",
    "    \"formatted_en.json\",\n",
    "    input_texts=formatted_en[\"input_text\"],\n",
    "    reference_texts=formatted_en[\"target_text\"],\n",
    ")\n",
    "\n",
    "save_variables_to_json(\n",
    "    \"formatted_train.json\",\n",
    "    input_texts=formatted_train[\"input_text\"],\n",
    "    reference_texts=formatted_train[\"target_text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7c01fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    # Tokenize targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"target_text\"],\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "    # Mask padding tokens in labels\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(token if token != tokenizer.pad_token_id else -100) for token in label_seq]\n",
    "        for label_seq in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_dataset = formatted_train.map(tokenize, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.filter(lambda x: any(label != -100 for label in x[\"labels\"]))\n",
    "\n",
    "tokenized_eval = formatted_en.map(tokenize, batched=True)\n",
    "tokenized_eval = tokenized_eval.filter(lambda x: any(label != -100 for label in x[\"labels\"]))\n",
    "\n",
    "# Assign to eval_dataset\n",
    "eval_dataset = tokenized_eval\n",
    "train_dataset = tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "328b75c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 19744\n",
      "Eval dataset size: 400\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Eval dataset size:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd61fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Training Arguments (faster logging & efficient eval)\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./mt5-detox-en-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=3,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir=\"./logs_en\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ‚úÖ Custom Trainer with fast generation & partial toxicity scoring\n",
    "class ToxicityPenaltyTrainer(Seq2SeqTrainer):\n",
    "    def __init__(self, *args, lambda_penalty=0.9, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.lambda_penalty = lambda_penalty\n",
    "        self.tox_tokenizer = AutoTokenizer.from_pretrained(\"unitary/toxic-bert\")\n",
    "        self.tox_model = AutoModelForSequenceClassification.from_pretrained(\"unitary/toxic-bert\").to(self.model.device)\n",
    "        self.tox_model.eval()\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        outputs = model(**inputs)\n",
    "        generation_loss = outputs.loss\n",
    "\n",
    "        # Compute penalty on 25% of the batch for efficiency\n",
    "        subset_size = max(1, inputs[\"input_ids\"].size(0) // 4)\n",
    "        sample_input_ids = inputs[\"input_ids\"][:subset_size]\n",
    "        sample_attention_mask = inputs[\"attention_mask\"][:subset_size]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_ids = model.generate(\n",
    "                input_ids=sample_input_ids,\n",
    "                attention_mask=sample_attention_mask,\n",
    "                max_length=30,\n",
    "                num_beams=1,\n",
    "                do_sample=False,\n",
    "                early_stopping=True,\n",
    "                decoder_start_token_id=self.tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "            decoded_texts = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            tox_inputs = self.tox_tokenizer(decoded_texts, return_tensors=\"pt\", truncation=True, padding=True).to(self.model.device)\n",
    "            tox_logits = self.tox_model(**tox_inputs).logits\n",
    "            tox_probs = torch.sigmoid(tox_logits[:, 0])\n",
    "            penalty = tox_probs.mean()\n",
    "\n",
    "        # Use a scaled non-linear penalty to avoid over-penalizing\n",
    "        penalty_weight = torch.tanh(self.lambda_penalty * penalty)\n",
    "        total_loss = generation_loss + penalty_weight\n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n",
    "\n",
    "# ‚úÖ Instantiate and train\n",
    "trainer = ToxicityPenaltyTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "    lambda_penalty=0.9,  # Adjust penalty weight\n",
    ")\n",
    "\n",
    "# üîÅ Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92646b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Path to your saved model\n",
    "checkpoint_path = \"mt5-detox-en-2/checkpoint-3399\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Send to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a52b06",
   "metadata": {},
   "source": [
    "## English Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11584702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"Helsinki-NLP/opus-mt-de-en\"\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate_de_to_en(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "translate_de_to_en = translate_de_to_en(formatted_de[\"input_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "036fc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detoxified: <pad> You are ugly</s>\n",
      "You are the worst piece of garbage.\n",
      "Nobody likes you.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"You are fucking ugly\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# Generate detoxified output\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_length=50,\n",
    "    num_beams=4,                      # optional: beam search improves fluency\n",
    "    early_stopping=True,              # stop generation when EOS is reached\n",
    "    decoder_start_token_id=tokenizer.pad_token_id  # force decoder to start properly\n",
    ")\n",
    "\n",
    "# Decode the generated output\n",
    "decoded = tokenizer.decode(output[0])\n",
    "print(\"Detoxified:\", decoded)\n",
    "\n",
    "def generate_detoxified(text):\n",
    "    input_text = \"detoxify (en): \" + text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    output_ids = model.generate(input_ids, max_length=128)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generate_detoxified(\"You are the worst piece of garbage.\"))\n",
    "print(generate_detoxified(\"Nobody likes you, idiot.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49a6e81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:09<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ‚úÖ Make sure you use the raw (non-tokenized) dataset\n",
    "# If you accidentally removed input_text/target_text earlier, re-load or cache it\n",
    "\n",
    "# üîß Batch size for faster inference (tune based on your GPU)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Collate function for batching text\n",
    "def collate_fn(batch):\n",
    "    texts = [ex[\"input_text\"] for ex in batch]\n",
    "    return tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# DataLoader\n",
    "loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "# Storage for results\n",
    "detoxified_outputs = []\n",
    "input_texts = []\n",
    "reference_texts = []\n",
    "\n",
    "# Run generation\n",
    "model.eval()\n",
    "for i, batch in enumerate(tqdm(loader)):\n",
    "    batch = {k: v.to(model.device) for k, v in batch.items()}\n",
    "    outputs = model.generate(\n",
    "        **batch,\n",
    "        max_length=50,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        decoder_start_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    \n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    detoxified_outputs.extend(decoded)\n",
    "\n",
    "    # Save corresponding original and reference text\n",
    "    for j in range(len(decoded)):\n",
    "        example = eval_dataset[i * BATCH_SIZE + j]\n",
    "        input_texts.append(example[\"input_text\"])\n",
    "        reference_texts.append(example[\"target_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44d63292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detoxified texts saved to detoxified_results.json ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save results to a JSON file\n",
    "output_data = {\n",
    "    \"input_texts\": input_texts,\n",
    "    \"reference_texts\": reference_texts,\n",
    "    \"detoxified_outputs\": detoxified_outputs\n",
    "}\n",
    "\n",
    "with open(\"detoxified_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Detoxified texts saved to detoxified_results.json ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1741ea0f",
   "metadata": {},
   "source": [
    "## BLEU Evaluation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e923430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.2632\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "#nltk.download(\"punkt_tab\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "smooth_fn = SmoothingFunction().method4\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "for hyp, ref in zip(detoxified_outputs, reference_texts):\n",
    "    hyp_tokens = nltk.word_tokenize(hyp)\n",
    "    ref_tokens = nltk.word_tokenize(ref)\n",
    "    \n",
    "    score = sentence_bleu(\n",
    "        [ref_tokens],\n",
    "        hyp_tokens,\n",
    "        smoothing_function=smooth_fn\n",
    "    )\n",
    "    bleu_scores.append(score)\n",
    "\n",
    "avg_bleu = np.mean(bleu_scores)\n",
    "print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb2a4f4",
   "metadata": {},
   "source": [
    "## Bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d867045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c48b5e31d434a6fa0c73d62f12ec086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ca4e0b06684725802221c1c3d8c44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.98 seconds, 406.16 sentences/sec\n",
      "Average BERTScore Precision:  0.9493\n",
      "Average BERTScore Recall:     0.9498\n",
      "Average BERTScore F1:         0.9494\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Use your lists from earlier\n",
    "# detoxified_outputs = [...]   # model-generated sentences\n",
    "# reference_texts = [...]      # ground truth neutral sentences\n",
    "\n",
    "P, R, F1 = score(detoxified_outputs, reference_texts, lang=\"en\", verbose=True)\n",
    "\n",
    "# Average scores\n",
    "print(f\"Average BERTScore Precision:  {P.mean():.4f}\")\n",
    "print(f\"Average BERTScore Recall:     {R.mean():.4f}\")\n",
    "print(f\"Average BERTScore F1:         {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a9f7d",
   "metadata": {},
   "source": [
    "## Toxicity Score Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8db40395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:    detoxify: then all of a sudden i see her , shes now got the big phony tits and everything .\n",
      "Detoxified:  then all of a sudden i see her, shes now got the big tits and everything.\n",
      "Toxicity Before: 0.93\n",
      "Toxicity After:  0.93\n",
      "--------------------------------------------------\n",
      "Original:    detoxify: My page should be protected first so that worthless scum like you can't keep vandalizing it.\n",
      "Detoxified:  My page should be protected first so that worthless stuff like you can't keep vandalizing it.\n",
      "Toxicity Before: 0.95\n",
      "Toxicity After:  0.55\n",
      "--------------------------------------------------\n",
      "Original:    detoxify: You made a mistake you ass.\n",
      "Detoxified:  You made a mistake.\n",
      "Toxicity Before: 0.97\n",
      "Toxicity After:  0.00\n",
      "--------------------------------------------------\n",
      "Average Toxicity Before: 0.92\n",
      "Average Toxicity After: 0.28\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from detoxify import Detoxify\n",
    "\n",
    "# Load Detoxify model\n",
    "toxicity_model = Detoxify('unbiased')\n",
    "\n",
    "# Run toxicity prediction\n",
    "toxicity_scores = toxicity_model.predict(input_texts)\n",
    "detoxified_scores = toxicity_model.predict(detoxified_outputs)\n",
    "\n",
    "# Print sample comparisons\n",
    "for i in range(3):\n",
    "    print(f\"Original:    {input_texts[i]}\")\n",
    "    print(f\"Detoxified:  {detoxified_outputs[i]}\")\n",
    "    print(f\"Toxicity Before: {toxicity_scores['toxicity'][i]:.2f}\")\n",
    "    print(f\"Toxicity After:  {detoxified_scores['toxicity'][i]:.2f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate average toxicity\n",
    "avg_toxicity_before = np.mean(toxicity_scores['toxicity'])\n",
    "avg_toxicity_after = np.mean(detoxified_scores['toxicity'])\n",
    "\n",
    "print(f\"Average Toxicity Before: {avg_toxicity_before:.2f}\")\n",
    "print(f\"Average Toxicity After: {avg_toxicity_after:.2f}\")\n",
    "\n",
    "# Plotting the distributions\n",
    "plt.hist(toxicity_scores['toxicity'], bins=20, alpha=0.5, label='Before Detox')\n",
    "plt.hist(detoxified_scores['toxicity'], bins=20, alpha=0.5, label='After Detox')\n",
    "plt.xlabel('Toxicity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Toxicity Score Distribution (Refined Model)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6792c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 30.232, p = 0.00000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Example: compare two arrays of toxicity scores\n",
    "before = np.array(toxicity_scores['toxicity'])\n",
    "after = np.array(detoxified_scores['toxicity'])\n",
    "\n",
    "t_stat, p_value = ttest_rel(before, after)\n",
    "print(f\"t = {t_stat:.3f}, p = {p_value:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
